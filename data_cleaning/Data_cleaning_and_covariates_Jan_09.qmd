---
title: "Fields COVID-19 dataset exploration"
author: "Ariel Mundo"
format: pdf
toc: true
toc-depth: 2
editor: source
urlcolor: blue
#bibliography: refs.bib
---

```{r, setup, echo=FALSE}
#| warning: false
library(tidyverse)
library(here)
library(lubridate)
library(patchwork)
library(visdat)
library(gt)
library(scales)
library(scico)

thm1<-scale_fill_scico_d(palette="buda",begin=0.3, end=0.8, direction = -1, aesthetics = "fill")

thm2<-scale_fill_scico_d(palette="oleron",begin=0.0, end=1.0, direction = -1, aesthetics = "fill")

thm3<-scale_fill_scico_d(palette="fes",begin=0.0, end=1.0, direction = -1, aesthetics = "fill")
```

# Background

This dataset is about vaccination and other COVID measures in different cities in Ontario. The covariates available are:

-   Age (only above 16, if age above 75 then it appears as 98)
-   Age-group (generated from age)
-   Employment status
-   Remote work within the last month
-   If person receives paid sick leave
-   Number of people in household
-   Number of people from household that attend school
-   Chronic illnesses within the household (*I will not analyze this one as the question is too open and asks about age and disease at the same time*)
-   Race
-   Three first digits of postal code
-   Day, month and year the survey was accessed

There are many responses from the survey on the dataset, but there are some that I would be interesed in analyzing:

-   "Have you received the first dose of the COVID vaccine?" (y/n)

-   (If answered "yes" above) "Have you received the second dose of the COVID vaccine?" (y/n)

-   (If answer was "no" to the first question) "If a vaccine was made available to you you would:"

          - definitely get
          - definitely not get
          - probably get
          - probably not get

**Note: As of Dec 30, 2022 I no longer intend to analyze this last question as after cleaning the dataset it has a missing rate of about 76% and therefore it has too few observations compared to the first two questions**.

# Preliminary Analyses

This document focuses on some preliminary analyses of the data I undertook to assess its representativeness. I performed five major tasks for this preliminary analysis:

-   Choosing covariates to assess their missigness rates
-   Cleaning the data in order to keep all the covariates with a 0% missigness rate
-   Race and ethnicity representativeness of the clean data
-   Trends in the survey answers by geographical location
-   Trends in survey answers by group age

Overall the goal of this analysis was to see what adjustments would need to be made to formally analyze the data.

As way of comparison, I used the 2016 census data for Ontario.

```{r,load-data,warning=FALSE,echo=FALSE}

#the dataframe has missing answers as blankspaces, need to change them all to NA

data<-tibble(read.csv(here("data","Fields_data.csv"),na.strings = c("")))

#set the time and date fields in the format that is required by lubridate

data$time_date_code<-ymd(data$time_date_code)
```


```{r, rename-columns,echo=FALSE,warning=FALSE}

#get a new dataframe and extract variables of interest and make them factors

#get the variables of interest, convert to factors those required
d1<-data%>%select(
  time_date_code,
  city,
  age,
  age_group,
  q02_first_dose,
  q02a_second_dose,
  q11_employed,
  q13_hh_size,
  q09_hh_income,
  q02b_vaccine,
  q16_race,
  q11a_work_remotely,
  q11b_sick_leave,
  q14_hh_attending_school,
  q24a_postal_first,
  q24b_postal_second,
  q24c_postal_third)%>%
  rename(date=time_date_code,
         first_dose=q02_first_dose,
         second_dose=q02a_second_dose,
         get_vaccine=q02b_vaccine,
         h_size=q13_hh_size,
         income=q09_hh_income,
         employed=q11_employed,
         race=q16_race,
         remote_work=q11a_work_remotely,
         sick_leave=q11b_sick_leave,
         school=q14_hh_attending_school,
         pc_1=q24a_postal_first,
         pc_2=q24b_postal_second,
         pc_3=q24c_postal_third
         )%>%
  mutate(across(c("age_group",
            "city",
            "employed",
            "h_size",
            "income",
            "race",
            "remote_work",
            "sick_leave",
            "school"),as.factor))
  
```

## Choosing covariates

The next step is to see from the covariates what are the ones with the highest number of missing observations, in order to decide what can we include in the model.

```{r}
#| echo: false
#| warning: false
#| tbl-cap: Percentage of missing observations \n all covariates

t1<-d1%>%
  select(age_group,
         employed,
         h_size,
         income,race,
         remote_work,
         sick_leave,
         school,
         pc_1,
         pc_2,
         pc_3)%>%
 summarise_all(funs(sum(!is.na(.)/length(.))))%>%#count percentage of NAs
  pivot_longer(everything())%>%
  arrange(desc(value))%>%
  rename(observations=value,
         variable=name)

#get actual observations
t2<-d1%>%
  select(age_group,
         employed,
         h_size,
         income,race,
         remote_work,
         sick_leave,
         school,
         pc_1,
         pc_2,
         pc_3)%>%
 summarise_all(funs(sum(is.na(.)/length(.))))%>%#count percentage of NAs
  pivot_longer(everything())%>%
  arrange(desc(value))%>%
  rename(missigness=value,
         variable=name)




#joining both to make table

t3<-left_join(t1,t2,by="variable")

#make table

t3%>%
  gt()%>%
  fmt_percent(
   columns=missigness,
    decimals=1)
  
```

From the table, it can be seen that the covariate with the least amount of observations is "sick_leave".

However, there are a couple of things we want to consider: The answer to "sick_leave" was answered only by those that reported to be employed (the survey design made this response conditional). Therefore, those unemployed would be excluded in an analysis that considers this variable.

At the very least, it would be interesting to analyze how the reported status of vaccination changed over geographical location and time by:

-   age group
-   income
-   race
-   employment status

From these covariates, the one with the highest missing rate of observations is the employment status. I next cleaned the data in order to have complete observations about employment, and to see how the missing rates looked for the other covariates.

```{r}
#| echo: false
#| warning: false
#| tbl-cap: Missing observations and histograms of the data
#| fig-width: 10

clean_data<-d1%>%
  select(age_group,
         employed,
         age,
         income,
         race,
         city,
         h_size,
         date,
         first_dose,
         second_dose,
         get_vaccine)%>%
  drop_na(employed)

### histogram plots to see issues about income, age and household #####

# clean_data%>%
#   ggplot(aes(x=age))+
#   geom_histogram(binwidth=10)+
#   facet_wrap(~income)


a<-d1%>%
  mutate(income_ord = fct_relevel(income,
                                   "under_15000",
                                   "15000_24999",
                                   "25000_39999",
                                   "40000_59999",
                                   "60000_89999",
                                   "90000_109999",
                                  "over_110000"
                                   ))%>%
 #drop_na(age,income,h_size)%>%
  ggplot(aes(x=age))+
  geom_histogram(binwidth=10)+
  facet_wrap(~income_ord)+
  ylim(c(0,1200))+
  theme(strip.text.x = element_text(size = 8))+
  theme_classic()+
  thm1

b<-d1%>%
  mutate(h_size_ord = fct_relevel(h_size,
                                   "1",
                                   "2",
                                   "3",
                                   "4",
                                   "5",
                                   "6",
                                   "7",
                                   "8",
                                   "9",
                                   "10_or_more"
                                   ))%>%
  #drop_na(age,income,h_size_ord)%>%
  ggplot(aes(x=age))+
  geom_histogram(binwidth=10)+
  facet_wrap(~h_size_ord)+
  ylim(c(0,200))+
  theme(strip.text.x = element_text(size = 8))+
  theme_classic()+
  thm1
 

c<-clean_data%>%
   mutate(income_ord = fct_relevel(income,
                                   "under_15000",
                                   "15000_24999",
                                   "25000_39999",
                                   "40000_59999",
                                   "60000_89999",
                                   "90000_109999",
                                  "over_110000"
                                   ))%>%
  ggplot(aes(x=age))+
  geom_histogram(binwidth=10)+
  facet_wrap(~income_ord)+
  theme(strip.text.x = element_text(size = 5))+
  theme_classic()+
  thm1

d<-clean_data%>%
   mutate(h_size_ord = fct_relevel(h_size,
                                   "1",
                                   "2",
                                   "3",
                                   "4",
                                   "5",
                                   "6",
                                   "7",
                                   "8",
                                   "9",
                                   "10_or_more"
                                   ))%>%
  #drop_na(age,income,h_size_ord)%>%
  ggplot(aes(x=age))+
  geom_histogram(binwidth=10)+
  facet_wrap(~h_size_ord)+
  ylim(c(0,200))+
  theme_classic()+
  theme(strip.text.x = element_text(size = 8))+
  thm1


a+b+plot_annotation(title="Original dataset")

c+d+plot_annotation(title="Clean dataset")


e<-clean_data%>%
  #drop_na(age,income,h_size_ord)%>%
  ggplot(aes(x=age,fill=employed))+
  geom_histogram(stat="count",binwidth=10)+
  #ylim(c(0,200))+
facet_wrap(~income)+
  theme_classic()+
  ggtitle("Clean dataset")+
  #theme(strip.text.x = element_text(size = 8))+
  thm1

f<-d1%>%
  #drop_na(age,income,h_size_ord)%>%
  ggplot(aes(x=age,fill=employed))+
  geom_histogram(stat="count",binwidth=10)+
  #ylim(c(0,200))+
facet_wrap(~income)+
  theme_classic()+
  ylim(c(0,100))+
  ggtitle("Original dataset")+
  #theme(strip.text.x = element_text(size = 8))+
  thm1


f+e



t4<-clean_data%>%
 summarise_all(funs(sum(is.na(.)/length(.))))%>% #count percentage of NAs
  pivot_longer(everything())%>%
  arrange(desc(value))%>%
  rename(missigness=value,
         variable=name)%>%
  gt()%>%
  fmt_percent(
   columns=missigness,
    decimals=1)
t4

```

There seem to be outliers where people \<25 y of age report having an income \>110k while living in a household of 1. Explore the reported household composition of those \<25 with income\>110k.

```{r,outliers}
outliers<-clean_data %>%
  filter(age_group=="16_24" &
           h_size==1 &
           income=="over_110000"
    
  )
  
outliers%>%
  ggplot(aes(x=h_size))+
  geom_histogram(stat="count")

#From the plot it is about 21 entries that are outliers. Now, remove these outliers

clean_data<-anti_join(clean_data,outliers)

```

This table shows something interesting due to the nature of the dataset: the missing observations across variables are different, which is why now, although in the original dataset there were more observations of "race" than "employment", when we select complete observations for the latter we lose some observations for race. The second step of cleaning would be to remove the missing observations from race as well, and see what the proportions of covariates and responses are when compared to the census data.

```{r,complete-obs}
#| echo: false
#| warning: false
#| tbl-cap: Clean dataset missigness


t7<-clean_data%>%
  drop_na(race)%>%
 summarise_all(funs(sum(is.na(.)/length(.))))%>% #count percentage of NAs
  pivot_longer(everything())%>%
  arrange(desc(value))%>%
  rename(missigness=value,
         variable=name)%>%
  gt()%>%
  fmt_percent(
   columns=missigness,
    decimals=1)
t7
```

It can be seen that after removing all missing observations in the covariates, the only response that still has missing observations is the answers for the second dose of the vaccine, with 27% of missing observations.

## Race and Ethnicity

Once the data was clean, I explored how the race and ethnicity information from the dataset compared to the data from the Census.

```{r,ethnic information}
#| echo: false
#| warning: false
#| tbl-cap: Ethnic information from the clean dataset
  t6<-clean_data%>%
    select(race)%>%
    group_by(race)%>%
    summarise(observations = n()) %>%
  mutate(percentage = observations / sum(observations))%>%
    gt()%>%
      fmt_percent(
   columns=percentage,
    decimals=1)
  
t6
```

Because the categories for race/ethnicity in the survey did not match the categories from the Canadian Census, we used a combination of sources to obtain the corresponding percentages to match the survey categories. Sources are indicated below:

- Fact sheet from the Provice of Ontario for Visible Minorities [link](https://www.ontario.ca/document/2016-census-highlights/fact-sheet-9-ethnic-origin-and-visible-minorities): Used to obtain percentages for Arab, Black, East Asian/Pacific Islander (adding Chinese, Korean, and Japanese percentages), Latin American, Mixed (using the percentage for "multiple visible minority"), Other (obtained by adding the Southeast Asian, Filipino, West Asian, and Minority not identified elsewhere percentages), South Asian. _Accessed on January 05, 2022_

- Census Profile for Ontario [link](https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/prof/details/page.cfm?Lang=E&Geo1=PR&Code1=35&Geo2=PR&Code2=01&SearchText=Ontario&SearchType=Begins&SearchPR=01&B1=Aboriginal%20peoples&TABID=1&type=1): Used to obtain percentage of Aboriginal population. _Accessed on January 05, 2022_

- Wikipedia entry for Ontario demographics [link](https://en.wikipedia.org/wiki/Demographics_of_Ontario): To corroborate that the percentage of population reported as "European" in this website matched the percentage obtained for "White Caucasian" that was independently obtained by obtaining the difference in population proportion after subtracting the sum of Visible Minorities and Aboriginal Population percentages.


| Ethnicity/Race | percentage |
|----------------|:-----------|
| Arab           | 1.6%       |
| Black          | 4.7%       |
| East Asian/Pacific Islander     | 6.6%       |
| Indigenous     | 2.8%       |
| Latin American | 1.5%       |
| Mixed          | 1.0%       |
| Other          | 5.2%       |
| South Asian    | 8.7%       |
| White Caucasian| 67.8%      |
| **Total**      | 99.9%      |
: Reference Data from Race/Ethnicity

Visible Minorities: 29.3%
Not a Visible Minority: 70.7% (Aboriginal 2.8%, White Caucasian 67.8%)


## Age groups

Another important aspect to consider is how the trends in the responses look over time by age group. This is because from the census data, the age groups for the province are as follows:

| Group age   | Percentage of population |
|-------------|:-------------------------|
| 15-24       | 12.7%                    |
| 25-34       | 12.9%                    |
| 35-44       | 12.8%                    |
| 45-54       | 14.9%                    |
| 55-64       | 13.7%                    |
| 65 and over | 16.7                     |

: Age distributions from the 2016 Census for Ontario

However, when plotted the proportion of answers at each time point among groups, the distribution looks rather different.

```{r,trends-by-age}
#| echo: false
#| warning: false
#| fig-height: 4
#| fig-width: 8
#| fig-cap: Age group distributions from the dataset

p2<-clean_data%>%
  select(age_group)%>%
   mutate(age_group_ord = fct_relevel(age_group,
                                      "16_24",
                                      "25_34",
                                      "35_44",
                                      "45_54",
                                      "55_64",
                                  "65_and_over"
                                          ))

  ggplot(p2%>%count(age_group_ord) %>%    # G count number in each group
         mutate(pct=n/sum(n),               # Calculate percent within each group
                ypos = 200),  # Calculate label positions
       aes(age_group_ord, n, fill=age_group_ord)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%"), y=ypos))+
  theme_classic()+
  thm1



```

It can be seen from the graph that the proportion of answers by group age do not follow the overall distribution from the province.

## Income

The question from the survey was "What is your household annual income?". To compare the results of this answer, we used the "Household total income groups in 2015 for private households" from the Census data (available in the Census Data for Ontario website [link](https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/prof/details/page.cfm?Lang=E&Geo1=PR&Code1=35&Geo2=PR&Code2=01&SearchText=Ontario&SearchType=Begins&SearchPR=01&B1=Income&TABID=1&type=1)). 

| Household income range (CAD) | Percentage |
|------------------------------|:-----------|
| \< 15,000                    | 5.7%       |
| 15,000 - 24,999              | 7.5%       |
| 25,000 - 39,999              | 11.6%      |
| 40,000- 59,999               | 15.4%      |
| 60,000 - 89,999              | 19.5%      |
| \>90,000                     | 40.3%      |

: Income percentages from the 2016 Census for Ontario

The brackets for income in the census data are different than the brackets used in the survey. The census does CAD 4,999 brackets (e.g., CAD 5,000- CAD 9,9999) up to CAD 49,999, followed by CAD 9,999 brackets up to CAD 99,999. After that, the brackets increase to CAD 24,999, and therefore, one cannot obtain percentages for the 90,000-109,999 and \>110,000 brackets from the survey.

Therefore, an additional category for income will be created in the dataset so it matches the information from the Census.

```{r,income}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-height: 4

clean_data<-clean_data%>%
    mutate(income_ord = case_when(
                                  income %in% "90000_109999" ~ "over_90000",
                                  income %in%"over_110000" ~ "over_90000",
                                  TRUE ~ as.character(income)
                                ))%>%
  mutate(income_ord=as.factor(income_ord))




p3<-clean_data%>%
  mutate(income_ord = fct_relevel(income_ord,
                                  "under_15000",
                                  "15000_24999",
                                  "25000_39999",
                                  "40000_59999",
                                  "60000_89999",
                                  "over_90000"
                                ))


ggplot(p3%>% count(income_ord)%>%  # count number in each group
         mutate(pct=n/sum(n),               # Calculate percent within each group
                ypos = 200),  # Calculate label positions
       aes(income_ord, n, fill=income_ord)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%"), y=ypos))+
  theme_classic()+
  thm2


```

Again, there are differences here in the patterns of response. The \<15,000 bracket accounts for about 20% of the responses, a much higher rate than the percentage they represent from the census, and there is variation within the other brackets as well.

## Geographical location

Next, we are interested in analyzing the geographical distribution of the answers the participants within the geographical areas defined by the Association of Municipalities from Ontario. 

**Update: the populations by census division/city were found on Jan 8, 2023 (from https://www12.statcan.gc.ca/census-recensement/2021/dp-pd/prof/index.cfm?Lang=E). The correction will be done using these numbers instead. The numbers can be found in `census_population_by_division.csv` in `data` directory.**

There are two parts to the geographical analysis:

1) Add to the dataset the data for the municipalities so each city has the corresponding region it belongs to.
1) Determine percentage of answers that correspond to Toronto. This is important because although the Census regions do not match the exact geographical boundaries of the municipalities and thus a direct correction for this cannot be easily obtained, Toronto is the largest urban area in the province and it is important to identify if corrections are needed with regard to the proportions from this place in the survey.

### Joining the municipalities data

We have obtained and cleaned the data of the municipalities from the province of Ontario [website](https://www.ontario.ca/page/list-ontario-municipalities#section-3), and cleaned the dataset to obtain the city names and geographical locations. Further details can be found in `municipalities.qmd` in the `data_cleaning` directory. We will join and match the geographical location from the municipalities dataset to the clean dataset we have obtained in this document so far after removing the entries that do not have a corresponding geographical location.

```{r,join-datasets}

clean_data<-clean_data%>%
  filter(city!="None")


municipalities<-read.csv(here("data","municipalities_clean.csv"))

municipalities$Municipal.status<-as.factor(municipalities$Municipal.status)

municipalities$Geographic.area<-as.factor(municipalities$Geographic.area)

municipalities$city<-as.factor(municipalities$city)


clean_data<-left_join(clean_data,municipalities,by="city")

```


Need to explore which entries were left without a geographical region:

```{r, missing-geog-area}

test<-clean_data %>%
  filter(is.na(Geographic.area))%>%
  distinct(city)

```


There are 2744 observations that did not get a geographical region, and they correspond to 187 unique cities. These will be exported to a csv file in order to manually write their geographical areas following the Association of Municipalities of Ontario divisions, and using Wikipedia to check the status of each municipality.

```{r,write-file}
#| echo: false

#write.csv(test,here("data","missing_municipalities.csv"),row.names = FALSE)

```

The code chunk above was ran once to get the names of the municipalities. After manually entering the geographic areas, the file was saved as `missing_municipalities_updated.csv`, and this will be the file to be used for the next steps.

Note: there is one city "Kinburn", but there are two communities with such name, one in Huron County and one in Carelton County, for the time being Huron County is assigned, will check later if is better to remove it. 

Also one occurence of "Sydenham", which can be a ward in Kingston or a community in Frotenac. Will assign Frotenac for the time being.

### Merging missing municipalities and geographic area names

After manually assigning the geographical regions to the municipalities that were missing (which can be found in `missing_municipalities.csv` in the `data` directory), these will be merged as the dataset `geographic_areas.csv` (also in `data`), which contains the titles for each region (e.g., "County", "Region").

```{r,merge-datasets-2}
#load missing municipalities dataset

missing_municipalities<-read.csv(here("data","missing_municipalities_updated.csv"))


#combining geographical regions

clean_data<-clean_data %>%
  left_join(missing_municipalities, by = c("city")) %>%
  mutate(Geographic.area = coalesce(Geographic.area.x,Geographic.area.y)) %>%
  select(-c(Geographic.area.x,Geographic.area.y))

clean_data$Geographic.area<-as.factor(clean_data$Geographic.area)

# load the the titles for each region

geographic_areas<-read.csv(here("data","geographic_areas.csv"))

geographic_areas$Geographic_area<-as.factor(geographic_areas$Geographic_area)

geographic_areas$Geographic_area_title <-as.factor(geographic_areas$Geographic_area_title)

#merge the datasets

clean_data <-left_join(clean_data,geographic_areas,by=c("Geographic.area"="Geographic_area")) %>%
   subset(select=-c(Full_title.y))
   
   
```




## Proportion of answers within Toronto

**This section needs to be modified as the correction has been done by geographical area on Jan 8, 2023**

The final step is of the geographical analysis is to determine the proportion of answers from Toronto.

```{r,plot-location}
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-height: 4
#| fig-cap: Percentage of survey answers by city



clean_data<-clean_data%>%
  mutate(location=as.character(case_when(city=="Toronto"~"Toronto",
                            city!="Toronto"~ "All other cities"
                          )))%>%
  mutate(location=as.factor(location))


ggplot(clean_data %>% count(location) %>%    # then count number in each group
         mutate(pct=n/sum(n),               # Calculate percent within each group
                ypos = 200),  # Calculate label positions
       aes(location, n, fill=location)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%"), y=ypos))+
  theme_classic()+
  thm1


```

The proportion of responses from the city of Toronto is 31.3% of the total in the clean dataset. From the (Census data)[https://www.toronto.ca/wp-content/uploads/2022/02/92e3-City-Planning-2021-Census-Backgrounder-Population-Dwellings-Backgrounder.pdf], the city of Toronto as of 2021 has a population of 2,794,356, corresponding to 19.6% of the total population of the Province.


# Health Regions approach

Following on a suggestion by BN on Jan 09, the idea is to use broader regions for geographical analysis. The Health Regions of Ontario will be used. However, these Health Regions do not match the census divisions. I have not been able to find a dataset from Health Ontario that lists each municipality and its corresponding Health Region. I will use a multi-stage approach to incorporate the information into the dataset:

- Get dataset from Paul Allen regarding long-term care homes in Ontario (https://paulallen.ca/consolidated-dataset-of-ltc-homes-in-ontario/). This dataset has communities and the Local Health Integration Network (LHINs) where long-term care homes were located. I will keep the community and LHIN information. 

- Add column for Health Region based on LHIN: The Health Regions substituted LHINs, a list of their correspondence can be found here: https://www.ontariohealth.ca/about-us/our-people. I will add this information. 

- Merge the dataset and check if there are missing municipalities. Manually add missing municipalities.

## Steps

The dataset from Paul Allen was downloaded and saved as `Consolidated_LTC_dataset.csv` in the `data` directory. One thing to note is that there is a missing observation (coded as "Not provided") for one of the entries (city of Napanee, located in the Lennox and Addington County). Under the LHIN divisions, Napanee was in the South East LHIN. Also, there is one entry that says "244 Main Street East" as the community entry but it should be "Stayner" (the address provided belongs to Stayner.) The information is fixed before adding the Health Region.

```{r,get-health-data}

#load data
ltc_data <- read.csv(here("data","Consolidated_LTC_dataset.csv"))

## checking missing observations

sum(ltc_data$X_LHIN=="Not provided")

ltc_data <- ltc_data %>%
  mutate(X_LHIN=replace(X_LHIN,X_LHIN=="Not provided","South East"))

ltc_data <- ltc_data %>%
  mutate(COMMUNITY=replace(COMMUNITY,COMMUNITY==" 244 Main Street East","Stayner"))

#keep relevant columns and add Health region information
ltc_data <-ltc_data %>%
 select(c("COMMUNITY","X_LHIN"))%>%
  rename(city=COMMUNITY,
         LHIN=X_LHIN)%>%
  mutate(Health_Region=
    case_when(LHIN=="Central"~ "Central",
              LHIN=="Central West"~"Central",
              LHIN=="Mississauga Halton"~"Central",
              LHIN=="North Simcoe Muskoka"~"Central",
              LHIN=="Central East"~"East",
              LHIN=="South East"~"East",
              LHIN=="Champlain"~"East",
              LHIN=="North East"~"North East",
              LHIN=="North West"~"North West",
              LHIN=="Toronto Central"~"Toronto",
              LHIN=="South West"~"West",
              LHIN=="Hamilton Niagara Haldimand Brant (Hnhb)"~"West",
              LHIN=="Waterloo Wellington"~"West",
              LHIN=="Erie St. Clair"~"West"
    )
  )%>%
  distinct(city,.keep_all = TRUE)


```




Now, combine datasets and write csv file for those cities that were not assigned a Health Region.

```{r,combine}

clean_data<-left_join(clean_data,ltc_data,by="city")


 missing_health_regions<-clean_data %>% filter(is.na(LHIN)) %>%
   distinct(city,.keep_all = TRUE)%>%
   select(city,Geographic.area,Geographic_area_title,LHIN,Health_Region)

#write.csv(missing_health_regions,here("data","missing_health_regions.csv"),row.names = FALSE)

```

To complete the missing LHIN information, the correspoding LHINs were obtained from the LHIN websites:

https://www.southeasthealthline.ca/aboutourregion.aspx?region=RuralFrontenacLennoxAddington

https://www.nsmhealthline.ca/aboutourregion.aspx

https://www.champlainhealthline.ca/aboutourregion.aspx?region=StormontDundasGlen


https://www.wwhealthline.ca/aboutourregion.aspx?region=KitchenerWaterlooWellesleyWilmotWoolwich



Some cities did not belong entirely to a LHIN. For example, Etobicoke was divided between the Central, Central East, and Toronto Central LHINs. We chose in these cases the LHIN that covered the larger geographical region of each city (Toronto Central LHIN in the case of Etobicoke). We now assign LHINs to the dataset and Health Regions. The dataset with the information of the missing LHINs is called `missing_health_regions_updated.csv`

```{r,merge-health-regions}

#load health regions with missing entries fixed

mhru<-read.csv(here("data","missing_health_regions_updated.csv"))

#rename columns
mhru <- mhru %>%
  rename(Geographic_area_title=Geographic.area.title)
  

clean_data<-clean_data %>%
  left_join(mhru, by = c("city")) %>%
   mutate(LHIN = coalesce(LHIN.x,LHIN.y)) %>%
  select(-c(LHIN.x,LHIN.y,Full_title.x,Geographic.area.y,Geographic_area_title.y))%>%
  mutate(Health_Region=
    case_when(LHIN=="Central"~ "Central",
              LHIN=="Central West"~"Central",
              LHIN=="Mississauga Halton"~"Central",
              LHIN=="North Simcoe Muskoka"~"Central",
              LHIN=="Central East"~"East",
              LHIN=="South East"~"East",
              LHIN=="Champlain"~"East",
              LHIN=="North East"~"North East",
              LHIN=="North West"~"North West",
              LHIN=="Toronto Central"~"Toronto",
              LHIN=="South West"~"West",
              LHIN=="Hamilton Niagara Haldimand Brant (Hnhb)"~"West",
              LHIN=="Waterloo Wellington"~"West",
              LHIN=="Erie St. Clair"~"West"
    ))%>%
  rename(Geographic_area=Geographic.area.x,Geographic_area_title=Geographic_area_title.x)


```


At this point, the data has been cleaned and prepared for formal analysis.

The clean dataset will be saved as a *.csv file.

```{r,save-clean-dataset}
#| echo: false

write.csv(clean_data,here("data","clean_dataset.csv"),row.names = FALSE)
```
